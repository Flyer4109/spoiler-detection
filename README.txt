Unfortunatly the code to collect the data can't be used because the secrets are secret to me.
The GUI for labelling the tweets can be seen in label_data. Click on tweet_labeller.html to run it.
The code for exploring the data can be running explore_data.py in the explore data file.
A vocabulary can be created by running create_vocab.py in preprocess_data.

And most importantly:
The LSTM can be trained by running train_rnn.py
You can run the best trained LSTM model in a GUI by running use_rnn.py.

The old code has be put in the OLD_CODE folder so that my progressive is viewable.

Required Python libraries:
Tweepy
NLTK
Matplotlib
seaborn
pandas
scipy
numpy
keras
tensorflow
flask

These are all be installed using the pip package. If any packages have been missed in this list they can be installed
through pip.